{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered test_dataset/en/audio/en_krishna_032.wav\n",
      "Filtered test_dataset/en/audio/en_krishna_026.wav\n",
      "Filtered test_dataset/en/audio/en_krishna_027.wav\n",
      "Filtered test_dataset/en/audio/en_krishna_033.wav\n",
      "Filtered test_dataset/en/audio/en_krishna_019.wav\n",
      "Filtered test_dataset/en/audio/en_krishna_025.wav\n",
      "Filtered test_dataset/en/audio/en_krishna_031.wav\n",
      "Filtered test_dataset/en/audio/en_krishna_030.wav\n",
      "Filtered test_dataset/en/audio/en_krishna_024.wav\n",
      "Filtered test_dataset/en/audio/en_krishna_018.wav\n",
      "Filtered test_dataset/en/audio/en_krishna_020.wav\n",
      "Filtered test_dataset/en/audio/en_krishna_034.wav\n",
      "Filtered test_dataset/en/audio/en_krishna_008.wav\n",
      "Filtered test_dataset/en/audio/en_krishna_009.wav\n",
      "Filtered test_dataset/en/audio/en_krishna_035.wav\n",
      "Filtered test_dataset/en/audio/en_krishna_021.wav\n",
      "Filtered test_dataset/en/audio/en_krishna_037.wav\n",
      "Filtered test_dataset/en/audio/en_krishna_023.wav\n",
      "Filtered test_dataset/en/audio/en_krishna_022.wav\n",
      "Filtered test_dataset/en/audio/en_krishna_036.wav\n",
      "Filtered test_dataset/en/audio/en_krishna_092.wav\n",
      "Filtered test_dataset/en/audio/en_krishna_086.wav\n",
      "Filtered test_dataset/en/audio/en_krishna_079.wav\n",
      "Filtered test_dataset/en/audio/en_krishna_051.wav\n",
      "Filtered test_dataset/en/audio/en_krishna_045.wav\n",
      "Filtered test_dataset/en/audio/en_krishna_044.wav\n",
      "Filtered test_dataset/en/audio/en_krishna_050.wav\n",
      "Filtered test_dataset/en/audio/en_krishna_078.wav\n",
      "Filtered test_dataset/en/audio/en_krishna_087.wav\n",
      "Filtered test_dataset/en/audio/en_krishna_093.wav\n",
      "Filtered test_dataset/en/audio/en_krishna_085.wav\n",
      "Filtered test_dataset/en/audio/en_krishna_091.wav\n",
      "Filtered test_dataset/en/audio/en_krishna_046.wav\n",
      "Filtered test_dataset/en/audio/en_krishna_052.wav\n",
      "Filtered test_dataset/en/audio/en_krishna_053.wav\n",
      "Filtered test_dataset/en/audio/en_krishna_047.wav\n",
      "Filtered test_dataset/en/audio/en_krishna_090.wav\n",
      "Filtered test_dataset/en/audio/en_krishna_084.wav\n",
      "Filtered test_dataset/en/audio/en_krishna_080.wav\n",
      "Filtered test_dataset/en/audio/en_krishna_094.wav\n",
      "Filtered test_dataset/en/audio/en_krishna_043.wav\n",
      "Filtered test_dataset/en/audio/en_krishna_057.wav\n",
      "Filtered test_dataset/en/audio/en_krishna_056.wav\n",
      "Filtered test_dataset/en/audio/en_krishna_042.wav\n",
      "Filtered test_dataset/en/audio/en_krishna_095.wav\n",
      "Filtered test_dataset/en/audio/en_krishna_081.wav\n",
      "Filtered test_dataset/en/audio/en_krishna_097.wav\n",
      "Filtered test_dataset/en/audio/en_krishna_083.wav\n",
      "Filtered test_dataset/en/audio/en_krishna_054.wav\n",
      "Filtered test_dataset/en/audio/en_krishna_040.wav\n",
      "Filtered test_dataset/en/audio/en_krishna_068.wav\n",
      "Filtered test_dataset/en/audio/en_krishna_069.wav\n",
      "Filtered test_dataset/en/audio/en_krishna_041.wav\n",
      "Filtered test_dataset/en/audio/en_krishna_055.wav\n",
      "Filtered test_dataset/en/audio/en_krishna_082.wav\n",
      "Filtered test_dataset/en/audio/en_krishna_096.wav\n",
      "Filtered test_dataset/en/audio/en_krishna_058.wav\n",
      "Filtered test_dataset/en/audio/en_krishna_070.wav\n",
      "Filtered test_dataset/en/audio/en_krishna_064.wav\n",
      "Filtered test_dataset/en/audio/en_krishna_065.wav\n",
      "Filtered test_dataset/en/audio/en_krishna_071.wav\n",
      "Filtered test_dataset/en/audio/en_krishna_059.wav\n",
      "Filtered test_dataset/en/audio/en_krishna_098.wav\n",
      "Filtered test_dataset/en/audio/en_krishna_067.wav\n",
      "Filtered test_dataset/en/audio/en_krishna_073.wav\n",
      "Filtered test_dataset/en/audio/en_krishna_072.wav\n",
      "Filtered test_dataset/en/audio/en_krishna_066.wav\n",
      "Filtered test_dataset/en/audio/en_krishna_099.wav\n",
      "Filtered test_dataset/en/audio/en_krishna_089.wav\n",
      "Filtered test_dataset/en/audio/en_krishna_062.wav\n",
      "Filtered test_dataset/en/audio/en_krishna_076.wav\n",
      "Filtered test_dataset/en/audio/en_krishna_077.wav\n",
      "Filtered test_dataset/en/audio/en_krishna_063.wav\n",
      "Filtered test_dataset/en/audio/en_krishna_088.wav\n",
      "Filtered test_dataset/en/audio/en_krishna_075.wav\n",
      "Filtered test_dataset/en/audio/en_krishna_061.wav\n",
      "Filtered test_dataset/en/audio/en_krishna_049.wav\n",
      "Filtered test_dataset/en/audio/en_krishna_048.wav\n",
      "Filtered test_dataset/en/audio/en_krishna_060.wav\n",
      "Filtered test_dataset/en/audio/en_krishna_074.wav\n",
      "Filtered test_dataset/en/audio/en_krishna_013.wav\n",
      "Filtered test_dataset/en/audio/en_krishna_007.wav\n",
      "Filtered test_dataset/en/audio/en_krishna_006.wav\n",
      "Filtered test_dataset/en/audio/en_krishna_012.wav\n",
      "Filtered test_dataset/en/audio/en_krishna_038.wav\n",
      "Filtered test_dataset/en/audio/en_krishna_004.wav\n",
      "Filtered test_dataset/en/audio/en_krishna_010.wav\n",
      "Filtered test_dataset/en/audio/en_krishna_011.wav\n",
      "Filtered test_dataset/en/audio/en_krishna_005.wav\n",
      "Filtered test_dataset/en/audio/en_krishna_039.wav\n",
      "Filtered test_dataset/en/audio/en_krishna_001.wav\n",
      "Filtered test_dataset/en/audio/en_krishna_015.wav\n",
      "Filtered test_dataset/en/audio/en_krishna_029.wav\n",
      "Filtered test_dataset/en/audio/en_krishna_028.wav\n",
      "Filtered test_dataset/en/audio/en_krishna_014.wav\n",
      "Filtered test_dataset/en/audio/en_krishna_016.wav\n",
      "Filtered test_dataset/en/audio/en_krishna_002.wav\n",
      "Filtered test_dataset/en/audio/en_krishna_003.wav\n",
      "Filtered test_dataset/en/audio/en_krishna_017.wav\n",
      "Filtered test_dataset/jp/audio/jp_krishna_014.wav\n",
      "Filtered test_dataset/jp/audio/jp_krishna_015.wav\n",
      "Filtered test_dataset/jp/audio/jp_krishna_001.wav\n",
      "Filtered test_dataset/jp/audio/jp_krishna_017.wav\n",
      "Filtered test_dataset/jp/audio/jp_krishna_003.wav\n",
      "Filtered test_dataset/jp/audio/jp_krishna_002.wav\n",
      "Filtered test_dataset/jp/audio/jp_krishna_016.wav\n",
      "Filtered test_dataset/jp/audio/jp_krishna_012.wav\n",
      "Filtered test_dataset/jp/audio/jp_krishna_006.wav\n",
      "Filtered test_dataset/jp/audio/jp_krishna_007.wav\n",
      "Filtered test_dataset/jp/audio/jp_krishna_013.wav\n",
      "Filtered test_dataset/jp/audio/jp_krishna_005.wav\n",
      "Filtered test_dataset/jp/audio/jp_krishna_011.wav\n",
      "Filtered test_dataset/jp/audio/jp_krishna_010.wav\n",
      "Filtered test_dataset/jp/audio/jp_krishna_004.wav\n",
      "Filtered test_dataset/jp/audio/jp_krishna_009.wav\n",
      "Filtered test_dataset/jp/audio/jp_krishna_008.wav\n",
      "Filtered test_dataset/jp/audio/jp_krishna_020.wav\n",
      "Filtered test_dataset/jp/audio/jp_krishna_018.wav\n",
      "Filtered test_dataset/jp/audio/jp_krishna_019.wav\n",
      "All files have been low-pass filtered at 4.7 kHz in place.\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from scipy.io.wavfile import read, write\n",
    "from scipy.signal import butter, filtfilt\n",
    "\n",
    "def lowpass_filter(data: np.ndarray, fs: int, cutoff: float, order: int = 6) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Apply a zero-phase Butterworth low-pass filter to a 1D or 2D audio array.\n",
    "    data:    np.ndarray of shape (n_samples,) or (n_samples, n_channels)\n",
    "    fs:      sampling rate in Hz\n",
    "    cutoff:  cutoff frequency in Hz\n",
    "    order:   filter order\n",
    "    \"\"\"\n",
    "    nyq = fs / 2\n",
    "    b, a = butter(order, cutoff / nyq, btype=\"low\", analog=False)\n",
    "\n",
    "    if data.ndim == 1:\n",
    "        return filtfilt(b, a, data)\n",
    "    else:\n",
    "        # apply per channel\n",
    "        filtered = np.zeros_like(data)\n",
    "        for ch in range(data.shape[1]):\n",
    "            filtered[:, ch] = filtfilt(b, a, data[:, ch])\n",
    "        return filtered\n",
    "\n",
    "# parameters\n",
    "CUTOFF_HZ = 4700.0  # 4.5 kHz\n",
    "FILTER_ORDER = 10\n",
    "LANGS = [\"en\", \"jp\"]\n",
    "\n",
    "for lang in LANGS:\n",
    "\n",
    "    audio_dir = Path(f\"./test_dataset/{lang}/audio\")\n",
    "    if not audio_dir.exists():\n",
    "        continue\n",
    "\n",
    "    for wav_path in audio_dir.glob(\"*.wav\"):\n",
    "        # read\n",
    "        fs, data = read(wav_path)\n",
    "\n",
    "        # filter\n",
    "        filtered = lowpass_filter(data.astype(float), fs, CUTOFF_HZ, FILTER_ORDER)\n",
    "\n",
    "        # overwrite\n",
    "        write(wav_path, fs, np.asarray(filtered, data.dtype))\n",
    "        print(f\"Filtered {wav_path}\")\n",
    "\n",
    "print(\"All files have been low-pass filtered at 4.7 kHz in place.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from utils.prompt_making import make_prompt\n",
    "\n",
    "DATA_DIR = Path(\"./test_dataset\")\n",
    "TRANS_FILES = {\n",
    "    \"en\": \"english_transcripts.csv\",\n",
    "    \"jp\": \"japanese_transcripts.csv\",\n",
    "}\n",
    "\n",
    "for lang, fname in TRANS_FILES.items():\n",
    "    csv_path = DATA_DIR / lang / fname\n",
    "    orig_dir = csv_path.parent / \"audio\"\n",
    "\n",
    "    # read once, skip bad lines if any\n",
    "    df = pd.read_csv(csv_path, engine=\"python\", on_bad_lines=\"skip\", encoding=\"utf-8\")\n",
    "\n",
    "    # iterate fast with itertuples\n",
    "    for row in df.itertuples(index=False):\n",
    "        audio_path = orig_dir / f\"{row.id}.wav\"\n",
    "        make_prompt(\n",
    "            name=f\"{row.id}\",\n",
    "            audio_prompt_path=str(audio_path),\n",
    "            transcript=row.text\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeonsang-eon/ECE6255_VALLEX/venv/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Generating variant: original ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EN / original:   0%|          | 0/96 [00:00<?, ?wav/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALL-E EOS [438 -> 837]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EN / original:   1%|          | 1/96 [00:15<24:38, 15.56s/wav]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALL-E EOS [589 -> 1310]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EN / original:   2%|▏         | 2/96 [00:45<37:11, 23.74s/wav]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALL-E EOS [549 -> 1068]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EN / original:   3%|▎         | 3/96 [01:11<38:23, 24.77s/wav]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALL-E EOS [274 -> 577]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EN / original:   4%|▍         | 4/96 [01:22<30:10, 19.68s/wav]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALL-E EOS [422 -> 946]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EN / original:   5%|▌         | 5/96 [01:44<30:49, 20.33s/wav]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALL-E EOS [274 -> 644]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EN / original:   6%|▋         | 6/96 [01:59<27:42, 18.48s/wav]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALL-E EOS [553 -> 1215]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EN / original:   7%|▋         | 7/96 [02:38<37:20, 25.18s/wav]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALL-E EOS [293 -> 716]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EN / original:   8%|▊         | 8/96 [02:54<32:46, 22.35s/wav]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALL-E EOS [593 -> 1273]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EN / original:   9%|▉         | 9/96 [03:25<36:24, 25.11s/wav]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALL-E EOS [209 -> 389]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EN / original:  10%|█         | 10/96 [03:32<27:46, 19.38s/wav]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALL-E EOS [424 -> 869]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EN / original:  11%|█▏        | 11/96 [03:51<27:32, 19.44s/wav]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALL-E EOS [283 -> 547]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EN / original:  12%|█▎        | 12/96 [04:03<23:55, 17.09s/wav]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALL-E EOS [413 -> 846]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EN / original:  14%|█▎        | 13/96 [04:29<27:18, 19.75s/wav]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALL-E EOS [438 -> 1013]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EN / original:  15%|█▍        | 14/96 [05:02<32:31, 23.80s/wav]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALL-E EOS [483 -> 901]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EN / original:  16%|█▌        | 15/96 [05:22<30:44, 22.77s/wav]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALL-E EOS [300 -> 786]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EN / original:  17%|█▋        | 16/96 [05:44<29:45, 22.32s/wav]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALL-E EOS [338 -> 680]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EN / original:  18%|█▊        | 17/96 [06:02<27:40, 21.02s/wav]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALL-E EOS [345 -> 832]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EN / original:  19%|█▉        | 18/96 [06:23<27:20, 21.03s/wav]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALL-E EOS [169 -> 460]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EN / original:  20%|█▉        | 19/96 [06:34<23:05, 17.99s/wav]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALL-E EOS [347 -> 828]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EN / original:  21%|██        | 20/96 [06:53<23:20, 18.43s/wav]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALL-E EOS [492 -> 977]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EN / original:  22%|██▏       | 21/96 [07:20<26:20, 21.07s/wav]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALL-E EOS [250 -> 538]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EN / original:  23%|██▎       | 22/96 [07:31<22:12, 18.01s/wav]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALL-E EOS [263 -> 515]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EN / original:  24%|██▍       | 23/96 [07:41<19:01, 15.63s/wav]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALL-E EOS [284 -> 809]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EN / original:  25%|██▌       | 24/96 [08:02<20:26, 17.04s/wav]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALL-E EOS [229 -> 496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EN / original:  26%|██▌       | 25/96 [08:13<18:09, 15.34s/wav]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALL-E EOS [382 -> 761]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EN / original:  27%|██▋       | 26/96 [08:30<18:38, 15.98s/wav]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALL-E EOS [371 -> 817]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EN / original:  28%|██▊       | 27/96 [08:49<19:06, 16.62s/wav]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALL-E EOS [239 -> 523]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EN / original:  29%|██▉       | 28/96 [08:59<16:40, 14.72s/wav]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALL-E EOS [370 -> 1004]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EN / original:  30%|███       | 29/96 [09:24<20:02, 17.95s/wav]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALL-E EOS [389 -> 869]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EN / original:  31%|███▏      | 30/96 [09:45<20:39, 18.78s/wav]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALL-E EOS [589 -> 1392]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EN / original:  32%|███▏      | 31/96 [10:21<25:58, 23.97s/wav]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALL-E EOS [302 -> 819]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EN / original:  33%|███▎      | 32/96 [10:39<23:38, 22.16s/wav]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALL-E EOS [326 -> 603]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EN / original:  34%|███▍      | 33/96 [10:53<20:39, 19.67s/wav]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALL-E EOS [192 -> 462]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EN / original:  35%|███▌      | 34/96 [11:05<17:59, 17.41s/wav]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALL-E EOS [716 -> 1490]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EN / original:  36%|███▋      | 35/96 [11:50<26:04, 25.65s/wav]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALL-E EOS [354 -> 770]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EN / original:  38%|███▊      | 36/96 [12:06<22:50, 22.84s/wav]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALL-E EOS [368 -> 684]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EN / original:  39%|███▊      | 37/96 [12:19<19:36, 19.94s/wav]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALL-E EOS [474 -> 1035]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EN / original:  40%|███▉      | 38/96 [12:44<20:32, 21.25s/wav]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALL-E EOS [394 -> 892]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EN / original:  41%|████      | 39/96 [13:15<23:09, 24.37s/wav]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALL-E EOS [206 -> 438]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EN / original:  42%|████▏     | 40/96 [13:25<18:33, 19.88s/wav]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALL-E EOS [304 -> 634]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EN / original:  42%|████▏     | 40/96 [13:40<19:08, 20.50s/wav]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 56\u001b[0m\n\u001b[1;32m     53\u001b[0m out_name   \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvariant\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.wav\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     54\u001b[0m out_path   \u001b[38;5;241m=\u001b[39m out_dir \u001b[38;5;241m/\u001b[39m out_name\n\u001b[0;32m---> 56\u001b[0m audio_array \u001b[38;5;241m=\u001b[39m \u001b[43mgen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_audio\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtranscript\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfile_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlanguage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlang\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccents\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlang\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m write_wav(\u001b[38;5;28mstr\u001b[39m(out_path), SAMPLE_RATE, audio_array)\n",
      "File \u001b[0;32m~/ECE6255_VALLEX/venv/lib/python3.10/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ECE6255_VALLEX/utils/generation.py:138\u001b[0m, in \u001b[0;36mgenerate_audio\u001b[0;34m(text, prompt, language, accent)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;66;03m# accent control\u001b[39;00m\n\u001b[1;32m    137\u001b[0m lang \u001b[38;5;241m=\u001b[39m lang \u001b[38;5;28;01mif\u001b[39;00m accent \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno-accent\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m token2lang[langdropdown2token[accent]]\n\u001b[0;32m--> 138\u001b[0m encoded_frames \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minference\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtext_tokens\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtext_tokens_lens\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m    \u001b[49m\u001b[43maudio_prompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m    \u001b[49m\u001b[43menroll_x_lens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menroll_x_lens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprompt_language\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlang_pr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtext_language\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlangs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43maccent\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mno-accent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlang\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;66;03m# Decode with Vocos\u001b[39;00m\n\u001b[1;32m    149\u001b[0m frames \u001b[38;5;241m=\u001b[39m encoded_frames\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/ECE6255_VALLEX/models/vallex.py:1173\u001b[0m, in \u001b[0;36mVALLE.inference\u001b[0;34m(self, x, x_lens, y, enroll_x_lens, top_k, temperature, prompt_language, text_language, best_of, length_penalty, return_worst)\u001b[0m\n\u001b[1;32m   1170\u001b[0m y_pos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnar_audio_position(y_pos)\n\u001b[1;32m   1171\u001b[0m xy_pos \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mconcat([x, y_pos], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m-> 1173\u001b[0m xy_dec, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnar_decoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1174\u001b[0m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[43mxy_pos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnar_stage_embeddings\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1175\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1176\u001b[0m logits \u001b[38;5;241m=\u001b[39m predict_layer(xy_dec[:, text_len \u001b[38;5;241m+\u001b[39m prefix_len :])\n\u001b[1;32m   1178\u001b[0m samples \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(logits, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/ECE6255_VALLEX/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ECE6255_VALLEX/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/ECE6255_VALLEX/modules/transformer.py:438\u001b[0m, in \u001b[0;36mTransformerEncoder.forward\u001b[0;34m(self, src, mask, src_key_padding_mask, return_layer_states)\u001b[0m\n\u001b[1;32m    436\u001b[0m output \u001b[38;5;241m=\u001b[39m src\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m mod \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m--> 438\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmod\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    439\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msrc_key_padding_mask\u001b[49m\n\u001b[1;32m    440\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    443\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm(output)\n",
      "File \u001b[0;32m~/ECE6255_VALLEX/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ECE6255_VALLEX/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/ECE6255_VALLEX/modules/transformer.py:297\u001b[0m, in \u001b[0;36mTransformerEncoderLayer.forward\u001b[0;34m(self, src, src_mask, src_key_padding_mask)\u001b[0m\n\u001b[1;32m    292\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[1;32m    293\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124monly bool and floating types of key_padding_mask are supported\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    294\u001b[0m         )\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm_first:\n\u001b[0;32m--> 297\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sa_block\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstage_embedding\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m        \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    300\u001b[0m \u001b[43m        \u001b[49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    302\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ff_block(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2(x, stage_embedding))\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/ECE6255_VALLEX/modules/transformer.py:360\u001b[0m, in \u001b[0;36mTransformerEncoderLayer._sa_block\u001b[0;34m(self, x, attn_mask, key_padding_mask)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_sa_block\u001b[39m(\n\u001b[1;32m    355\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    356\u001b[0m     x: Tensor,\n\u001b[1;32m    357\u001b[0m     attn_mask: Optional[Tensor],\n\u001b[1;32m    358\u001b[0m     key_padding_mask: Optional[Tensor],\n\u001b[1;32m    359\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 360\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    361\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    362\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    363\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    364\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    365\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    366\u001b[0m \u001b[43m        \u001b[49m\u001b[43mneed_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    367\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    368\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout1(x)\n",
      "File \u001b[0;32m~/ECE6255_VALLEX/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ECE6255_VALLEX/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/ECE6255_VALLEX/modules/activation.py:566\u001b[0m, in \u001b[0;36mMultiheadAttention.forward\u001b[0;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights)\u001b[0m\n\u001b[1;32m    541\u001b[0m     attn_output, attn_output_weights \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mmulti_head_attention_forward(\n\u001b[1;32m    542\u001b[0m         query,\n\u001b[1;32m    543\u001b[0m         key,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    563\u001b[0m         average_attn_weights\u001b[38;5;241m=\u001b[39maverage_attn_weights,\n\u001b[1;32m    564\u001b[0m     )\n\u001b[1;32m    565\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 566\u001b[0m     attn_output, attn_output_weights \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmulti_head_attention_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    567\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    568\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    569\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    570\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    571\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_heads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    572\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_proj_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    573\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_proj_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    574\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias_k\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    575\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias_v\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    576\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_zero_attn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    577\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    578\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_proj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    579\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_proj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    580\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    581\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[43m        \u001b[49m\u001b[43mneed_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mneed_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    584\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage_attn_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maverage_attn_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    585\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    586\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first \u001b[38;5;129;01mand\u001b[39;00m is_batched:\n\u001b[1;32m    587\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m attn_output\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m), attn_output_weights\n",
      "File \u001b[0;32m~/ECE6255_VALLEX/venv/lib/python3.10/site-packages/torch/nn/functional.py:6410\u001b[0m, in \u001b[0;36mmulti_head_attention_forward\u001b[0;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   6407\u001b[0m k \u001b[38;5;241m=\u001b[39m k\u001b[38;5;241m.\u001b[39mview(bsz, num_heads, src_len, head_dim)\n\u001b[1;32m   6408\u001b[0m v \u001b[38;5;241m=\u001b[39m v\u001b[38;5;241m.\u001b[39mview(bsz, num_heads, src_len, head_dim)\n\u001b[0;32m-> 6410\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m \u001b[43mscaled_dot_product_attention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   6411\u001b[0m \u001b[43m    \u001b[49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdropout_p\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_causal\u001b[49m\n\u001b[1;32m   6412\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6413\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   6414\u001b[0m     attn_output\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m)\u001b[38;5;241m.\u001b[39mcontiguous()\u001b[38;5;241m.\u001b[39mview(bsz \u001b[38;5;241m*\u001b[39m tgt_len, embed_dim)\n\u001b[1;32m   6415\u001b[0m )\n\u001b[1;32m   6417\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m linear(attn_output, out_proj_weight, out_proj_bias)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from scipy.io.wavfile import write as write_wav\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import utils.generation as gen\n",
    "from utils.generation import SAMPLE_RATE\n",
    "from train_utils.icefall.utils import load_checkpoint\n",
    "\n",
    "# 1) Preload models once\n",
    "gen.preload_models()\n",
    "\n",
    "# 2) Checkpoints\n",
    "checkpoint_paths = {\n",
    "    \"original\":   \"./checkpoints/vallex-checkpoint.pt\",\n",
    "    \"pure\":       \"./checkpoints/checkpoint-30-pure.pt\",\n",
    "    \"LoRA_whole\": \"./checkpoints/checkpoint-30-whole.pt\",\n",
    "    \"LoRA_AR\":    \"./checkpoints/checkpoint-30-AR.pt\",\n",
    "    \"LoRA_NAR\":   \"./checkpoints/checkpoint-30-NAR.pt\",\n",
    "}\n",
    "\n",
    "# 3) CSV mappings\n",
    "DATA_DIR = Path(\"./test_dataset\")\n",
    "TRANS_FILES = {\n",
    "    \"en\": \"english_transcripts.csv\",\n",
    "    \"jp\": \"japanese_transcripts.csv\",\n",
    "}\n",
    "\n",
    "# 4) Accent labels\n",
    "accents = {\"en\": \"English\", \"jp\": \"日本語\"}\n",
    "\n",
    "# 5) Iterate variants → languages → rows with tqdm\n",
    "for variant, ckpt_path in checkpoint_paths.items():\n",
    "    print(f\"\\n=== Generating variant: {variant} ===\")\n",
    "    if variant != \"original\":\n",
    "        load_checkpoint(ckpt_path, gen.model, None, None, None)\n",
    "\n",
    "    for lang, csv_name in TRANS_FILES.items():\n",
    "        csv_path = DATA_DIR / lang / csv_name\n",
    "        df = pd.read_csv(csv_path, engine=\"python\", on_bad_lines=\"skip\", encoding=\"utf-8\")\n",
    "\n",
    "        out_dir = DATA_DIR / lang / variant\n",
    "        out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        # tqdm progress bar per file\n",
    "        for row in tqdm(df.itertuples(index=False),\n",
    "                        total=len(df),\n",
    "                        desc=f\"{lang.upper()} / {variant}\",\n",
    "                        unit=\"wav\"):\n",
    "            file_id    = row.id\n",
    "            transcript = row.text\n",
    "            out_name   = f\"{file_id}_{variant}.wav\"\n",
    "            out_path   = out_dir / out_name\n",
    "\n",
    "            audio_array = gen.generate_audio(\n",
    "                text=transcript,\n",
    "                prompt=file_id,\n",
    "                language=lang,\n",
    "                accent=accents[lang]\n",
    "            )\n",
    "            write_wav(str(out_path), SAMPLE_RATE, audio_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa, librosa.display\n",
    "import pyworld as pw\n",
    "import parselmouth\n",
    "import soundfile as sf\n",
    "from scipy.io.wavfile import write as write_wav\n",
    "from language_tool_python import LanguageTool\n",
    "\n",
    "# ─── 기존 함수들 ───────────────────────────────────────────────────────────\n",
    "\n",
    "def ensure_dir(d: Path):\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def plot_waveform(y, sr, out_path: Path, title: str):\n",
    "    plt.figure(figsize=(10,3))\n",
    "    librosa.display.waveshow(y, sr=sr, color='red')\n",
    "    plt.title(f\"{title} waveform\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_path)\n",
    "    plt.close()\n",
    "\n",
    "def plot_spectrogram(y, sr, out_path: Path, title: str):\n",
    "    D = librosa.stft(y, n_fft=1024, hop_length=256)\n",
    "    S_db = librosa.amplitude_to_db(np.abs(D), ref=np.max)\n",
    "    plt.figure(figsize=(10,4))\n",
    "    librosa.display.specshow(S_db, sr=sr, hop_length=256, x_axis='time', y_axis='hz')\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "    plt.title(f\"{title} spectrogram\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_path)\n",
    "    plt.close()\n",
    "\n",
    "def extract_pitch_sp(y, sr):\n",
    "    y64 = y.astype(np.float64)\n",
    "    f0, t = pw.harvest(y64, sr)\n",
    "    f0v = f0[f0>0]\n",
    "    return {\n",
    "        'f0_contour': f0,\n",
    "        'f0_mean': float(np.nanmean(f0v)),\n",
    "        'f0_std':  float(np.nanstd(f0v))\n",
    "    }\n",
    "\n",
    "def extract_formant_jitter_shimmer_hnr(path):\n",
    "    snd = parselmouth.Sound(path)\n",
    "    form = snd.to_formant_burg()\n",
    "    t = np.linspace(snd.xmin, snd.xmax, 100)\n",
    "    f1 = [form.get_value_at_time(1, ti) for ti in t]\n",
    "    f2 = [form.get_value_at_time(2, ti) for ti in t]\n",
    "    f3 = [form.get_value_at_time(3, ti) for ti in t]\n",
    "    pp = parselmouth.praat.call(snd, \"To PointProcess (periodic, cc)\", 75.0, 600.0)\n",
    "    jitter  = parselmouth.praat.call(pp, \"Get jitter (local)\", 0, 0, 0.0001, 0.02, 1.3)\n",
    "    shimmer = parselmouth.praat.call([snd,pp], \"Get shimmer (local)\", 0, 0, 0.0001, 0.02, 1.3, 1.6)\n",
    "    hnr_obj = parselmouth.praat.call(snd, \"To Harmonicity (cc)\", 0.01, 75.0, 0.1, 4.5)\n",
    "    hnr     = parselmouth.praat.call(hnr_obj, \"Get mean\", 0, 0)\n",
    "    return {\n",
    "        'F1_mean': np.nanmean(f1),\n",
    "        'F2_mean': np.nanmean(f2),\n",
    "        'F3_mean': np.nanmean(f3),\n",
    "        'jitter': float(jitter),\n",
    "        'shimmer': float(shimmer),\n",
    "        'hnr': float(hnr)\n",
    "    }\n",
    "\n",
    "def extract_errors(text: str):\n",
    "    tool = LanguageTool('en-US', remote_server='https://api.languagetool.org')\n",
    "    matches = tool.check(text)\n",
    "    return {(m.offset, m.offset + m.errorLength, m.ruleId) for m in matches}\n",
    "\n",
    "def grammar_fidelity(orig_text: str, synth_text: str):\n",
    "    orig_errs  = extract_errors(orig_text)\n",
    "    synth_errs = extract_errors(synth_text)\n",
    "    tp = len(orig_errs & synth_errs)\n",
    "    fn = len(orig_errs - synth_errs)\n",
    "    fp = len(synth_errs - orig_errs)\n",
    "    recall    = tp / (tp + fn) if tp+fn else 1.0\n",
    "    precision = tp / (tp + fp) if tp+fp else 1.0\n",
    "    f1        = 2*precision*recall/(precision+recall) if (precision+recall) else 0.0\n",
    "    return precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # 1) CSV 읽어서 id->text 맵 생성\n",
    "    transcripts = {}\n",
    "    for lang, fname in [('en','english_transcripts.csv'),\n",
    "                        ('jp','japanese_transcripts.csv')]:\n",
    "        df = pd.read_csv(f\"./test_dataset/{lang}/{fname}\", engine=\"python\", on_bad_lines=\"skip\", encoding=\"utf-8\")\n",
    "        transcripts[lang] = {row.id: row.text for row in df.itertuples(index=False)}\n",
    "\n",
    "    # 2) 평가할 디렉토리 구성\n",
    "    ref_dirs = {\n",
    "        'en': Path(\"./test_dataset/en/audio\"),\n",
    "        'jp': Path(\"./test_dataset/jp/audio\"),\n",
    "    }\n",
    "    variants = [\"original\",\"pure\",\"LoRA_whole\",\"LoRA_AR\",\"LoRA_NAR\"]\n",
    "\n",
    "    # 3) 출력 결과 저장할 최상위 폴더\n",
    "    OUT_ROOT = Path(\"results\")\n",
    "    \n",
    "    for lang in ['en','jp']:\n",
    "        # 원본(참조) 오디오/텍스트 맵\n",
    "        ref_map = {p.stem.split('_',1)[-1]: p for p in ref_dirs[lang].glob(\"*.wav\")}\n",
    "        \n",
    "        for variant in variants:\n",
    "            syn_dir = Path(f\"./test_dataset/{lang}/{variant}\")\n",
    "            if not syn_dir.is_dir(): continue\n",
    "\n",
    "            for syn_path in syn_dir.glob(\"*.wav\"):\n",
    "                # 파일명: ex) en_krishna_001_original.wav\n",
    "                stem = syn_path.stem\n",
    "                # id만 뽑아내기\n",
    "                core = stem\n",
    "                # \"en_\" 제거\n",
    "                if core.startswith(f\"{lang}_\"):\n",
    "                    core = core[len(lang)+1:]\n",
    "                # \"_{variant}\" 제거\n",
    "                if core.endswith(f\"_{variant}\"):\n",
    "                    core = core[:-(len(variant)+1)]\n",
    "                rec_id = core\n",
    "\n",
    "                # 참조 오디오\n",
    "                if rec_id not in ref_map:\n",
    "                    print(f\"⚠️  {lang}/{variant}: 참조 오디오 {rec_id} 없음, 건너뜁니다.\")\n",
    "                    continue\n",
    "                ref_path = ref_map[rec_id]\n",
    "\n",
    "                # transcript\n",
    "                text = transcripts[lang].get(rec_id, \"\")\n",
    "                if not text:\n",
    "                    print(f\"⚠️  {lang}/{variant}: 텍스트 {rec_id} 없음\")\n",
    "                    continue\n",
    "\n",
    "                # 평가 결과 저장 폴더\n",
    "                out_dir = OUT_ROOT / lang / variant / rec_id\n",
    "                ensure_dir(out_dir)\n",
    "\n",
    "                # 4) 오디오 로드\n",
    "                y_ref, sr = librosa.load(str(ref_path), sr=16000)\n",
    "                y_syn, _  = librosa.load(str(syn_path), sr=16000)\n",
    "\n",
    "                # 5) 플롯\n",
    "                plot_waveform   (y_ref, sr, out_dir/\"ref_waveform.png\",   f\"{rec_id} ref\")\n",
    "                plot_spectrogram(y_ref, sr, out_dir/\"ref_spectrogram.png\",f\"{rec_id} ref\")\n",
    "                plot_waveform   (y_syn, sr, out_dir/\"syn_waveform.png\",   f\"{rec_id} syn\")\n",
    "                plot_spectrogram(y_syn, sr, out_dir/\"syn_spectrogram.png\",f\"{rec_id} syn\")\n",
    "\n",
    "                # 6) 특징 추출\n",
    "                p_ref = extract_pitch_sp(y_ref, sr)\n",
    "                p_syn = extract_pitch_sp(y_syn, sr)\n",
    "                f_ref = extract_formant_jitter_shimmer_hnr(str(ref_path))\n",
    "                f_syn = extract_formant_jitter_shimmer_hnr(str(syn_path))\n",
    "\n",
    "                # 텍스트 평가는 같은 텍스트를 비교하므로, 완전 일치 F1 = 1.0\n",
    "                prec, rec, f1 = grammar_fidelity(text, text)\n",
    "\n",
    "                # 7) 콘솔 요약 출력\n",
    "                print(f\"\\n─── [{lang}/{variant}/{rec_id}] ───\")\n",
    "                print(f\"Pitch mean  ref {p_ref['f0_mean']:.1f}Hz  | syn {p_syn['f0_mean']:.1f}Hz\")\n",
    "                print(f\"Formant1    ref {f_ref['F1_mean']:.1f}Hz | syn {f_syn['F1_mean']:.1f}Hz\")\n",
    "                print(f\"Jitter      ref {f_ref['jitter']:.6f}   | syn {f_syn['jitter']:.6f}\")\n",
    "                print(f\"HNR         ref {f_ref['hnr']:.3f}   | syn {f_syn['hnr']:.3f}\")\n",
    "                print(f\"Grammar F1      {f1:.3f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
